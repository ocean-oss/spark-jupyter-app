---
ocean:
  version: "1"
steps:
  - engines:
    - name: spark
      vars:
        - name: spark_master_host
          value: "{{ engines.spark.deployment.nodes.main.private_ip }}"
        - name: spark_master_port
          value: reserve_port()
        - name: spark_master_ui_port
          value: reserve_port()
        - name: spark_worker_port
          value: reserve_port()
        - name: spark_worker_ui_port
          value: reserve_port()
        - name: spark_master_url
          value: "spark://{{ engines.spark.vars.spark_master_host }}:{{ engines.spark.vars.spark_master_port }}"
      orchestrator:
        type: Orchestrator::MainWithWorkers
        deploy_to_main: true
        deploy_to_workers: true
        snapshot:
          registry:
            name: docker_hub
          image:
            name: jupyter/all-spark-notebook
          name: latest
        container:
          user: root
          workdir: /work
          mounts:
            engine: /etc/ocean
            data_stores: "{{ engines.spark.orchestrator.container.workdir }}"
            ssh: "/home/{{ workspace.user.name }}/.ssh"
          nodes:
            main:
              command: "{{ engines.spark.orchestrator.container.mounts.engine }}/master_startup.sh"
              env_vars:
                - name: NB_UID
                  value: "{{ workspace.user.uid }}"
                - name: NB_GID
                  value: "{{ workspace.user.gid }}"
                - name: CHOWN_HOME
                  value: yes
                - name: GRANT_SUDO
                  value: yes
            worker:
              command: "{{ engines.spark.orchestrator.container.mounts.engine }}/worker_startup.sh"
              env_vars:
                - name: NB_UID
                  value: "{{ workspace.user.uid }}"
                - name: NB_GID
                  value: "{{ workspace.user.gid }}"
                - name: CHOWN_HOME
                  value: yes
                - name: GRANT_SUDO
                  value: yes
      ui:
        buttons:
          - node_target: main
            label: Spark Master UI
            url: "http://{{ engines.spark.ui.buttons.self.node.public_ip }}:{{ engines.spark.vars.spark_master_ui_port }}"
          - node_target: workers
            label: Spark Worker UI
            url: "http://{{ engines.spark.ui.buttons.self.node.public_ip }}:{{ engines.spark.vars.spark_worker_ui_port }}"
  - engines:
    - name: jupyter
      vars:
        - name: jupyter_port
          value: reserve_port()
        - name: jupyter_token
          value: generate_uuid()
      orchestrator:
        type: Orchestrator::MainWithWorkers
        deploy_to_main: true
        deploy_to_workers: false
        snapshot:
          registry:
            name: docker_hub
          image:
            name: jupyter/all-spark-notebook
          name: latest
        container:
          user: root
          workdir: /work
          mounts:
            engine: /etc/ocean
            data_stores: "{{ engines.spark.orchestrator.container.workdir }}"
            ssh: "/home/{{ workspace.user.name }}/.ssh"
          nodes:
            main:
              command: "{{ engines.jupyter.orchestrator.container.mounts.engine }}/master_startup.sh"
              env_vars:
                - name: JUPYTER_ENABLE_LAB
                  value: yes
                - name: NB_UID
                  value: "{{ workspace.user.uid }}"
                - name: NB_GID
                  value: "{{ workspace.user.gid }}"
                - name: CHOWN_HOME
                  value: yes
                - name: GRANT_SUDO
                  value: yes
                - name: RESTARTABLE
                  value: yes
                - name: SPARK_MASTER
                  value: "{{ engines.spark.vars.spark_master_url }}"
      ui:
        buttons:
          - node_target: main
            label: Jupyter Notebook
            url: "http://{{ engines.jupyter.ui.buttons.self.node.public_ip }}:{{ engines.jupyter.vars.jupyter_port }}"